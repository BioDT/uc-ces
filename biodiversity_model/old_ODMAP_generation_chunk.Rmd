---
title: "BioDT biodiversity model"
date: "`r Sys.Date()`"
output: html_document
params:
  taxonkey: 5334220
  out_file: "untitled.tif"
  n_bootraps: 5
---

```{r, message = FALSE, warning = FALSE}
input_list = readRDS(file.path(getwd(), "ODMAP_template_list.RDS"))

# Generate template dictionary
odmap_dict <- read_csv("odmap_dict.csv")
completed_fields <- read.csv("C:/Users/dylcar/OneDrive - UKCEH/Desktop/BioDT/uc-ces/metadata/biodiversity_model_od_map_fields.csv")
odmap_dict <- left_join(odmap_dict, completed_fields)

# Load your SpatRaster object (replace 'raster_object' with your actual object)
output_raster_object <- rast("untitled.tif")

# Define a function to search the script code use
script_search <- function(regex) {
lines <- readLines("biodiversity_model_workflow_flexsdm_ODMAP.Rmd")
any(sapply(lines, FUN = function(line){
  trimmed_line <- trimws(line) # Remove leading and trailing whitespace
  searches = !startsWith(trimmed_line, "#") && grepl(regex, trimmed_line) && !grepl("script_search", trimmed_line)
}))
}

# Function to obtain a description for a given ID from a dictionary data frame
obtain_description <- function(id) {
  # Check if the ID exists in the dictionary
  if (!(id %in% odmap_dict$element_id)) {
    last_underscore <- max(gregexpr("_", id)[[1]])
    id <- substr(id, 1, last_underscore - 1)
  }

  # Retrieve description and text entry for the ID
  description = odmap_dict %>% filter(element_id == id) %>% pull(element_placeholder)
  text_entry = odmap_dict %>% filter(element_id == id) %>% pull(Value)

  # Print the description and text entry if available
  if (!is.na(text_entry) && identical(text_entry, character(0)) == FALSE && text_entry != "") {
    print(paste0(description, "    Entry found: ", text_entry))
  } else {
    print(description)
  }
}

# Function to obtain elements in each subsection from a dictionary data frame
obtain_subsection_ids <- function(section_name, subsection_text) {
  # Filter the dictionary for the given subsection
  odmap_dict_sub = odmap_dict %>% filter(section == section_name, subsection == subsection_text)
  elements = odmap_dict_sub$element_id

  # Process names in the input list
  input_list_stemmed_names = unlist(sapply(names(input_list), USE.NAMES = F, FUN = function(name) {
    last_underscore <- max(gregexpr("_", name)[[1]])
    substr(name, 1, last_underscore - 1)
  }))

  # Print the names of elements in the subsection
  for (i in seq_along(elements)) {

    nums = which(input_list_stemmed_names == elements[i])

    if (length(nums) == 0){

      print(elements[i])
    }

    else{

      print(names(input_list)[nums])
    }
  }

}

obtain_subsection_ids(section_name = "Model", "Model settings")

### Subsections

#### Overview ####
### Authorship ###
obtain_subsection_ids(section_name = "Overview", "Authorship")

obtain_description("o_authorship_1")
input_list$o_authorship_1 = "BioDT species distribution models"

obtain_description("o_authorship_3")
input_list$o_authorship_3 = "simrol@ceh.ac.uk; dylcar@ceh.ac.uk"

obtain_description("o_authorship_4")
input_list$o_authorship_4 = ""

### Model objective ###
obtain_subsection_ids(section_name = "Overview", "Model objective") 

obtain_description("o_objective_1")
input_list$o_objective_1 = "Mapping and interpolation"

obtain_description("o_objective_2")
input_list$o_objective_2 = "Maps of species presence"

### Focal Taxon ###
obtain_subsection_ids(section_name = "Overview", "Focal Taxon") 
obtain_description("o_taxon_1")
input_list$o_taxon_1 = target_species

### Location ###
obtain_subsection_ids(section_name = "Overview", "Location") 

obtain_description("o_location_1")
input_list$o_location_1 = "Cairngorms National Park, United Kingdom"

### scale of analysis ###
obtain_subsection_ids(section_name = "Overview", "Scale of Analysis")

# Get the extent coordinates
extent <- ext(output_raster_object)
# Additional field that records URL
input_list$location_url = "https://cairngorms.co.uk/"
# Obtain longitude and latitude coordinates bounding the tif file
obtain_description("o_scale_1_xmin")
input_list$o_scale_1_xmin = as.character(extent[1])
obtain_description("o_scale_1_xmax")
input_list$o_scale_1_xmax = as.character(extent[2])
obtain_description("o_scale_1_ymin")
input_list$o_scale_1_ymin = as.character(extent[3])
obtain_description("o_scale_1_ymax")
input_list$o_scale_1_ymax = as.character(extent[4])

obtain_description("o_scale_2")
input_list$o_scale_2 = "0.1 m"
obtain_description("o_scale_3")
input_list$o_scale_3 = "There is no temporal extent to the analysis"
obtain_description("o_scale_4")
input_list$o_scale_4 = "There is no temporal resolution to the analysis"
obtain_description("o_scale_5")
input_list$o_scale_5 = "political"

### Biodiversity data ###
obtain_subsection_ids(section_name = "Overview", "Biodiversity data")

obtain_description("o_bio_1")
input_list$o_bio_1 = "citizen science; field survey"
obtain_description("o_bio_2")
input_list$o_bio_2 = "point occurrence"

### Hypothesis ###
obtain_subsection_ids(section_name = "Overview", "Hypotheses") 

obtain_description("o_concept_1")
input_list$o_concept_1 = paste("investigating how environment variables affect the distributions of the species,", target_species, "in the Cairngorms National Park")

### Assumptions ###
obtain_subsection_ids(section_name = "Overview", "Assumptions")

obtain_description("o_assumptions_1")
input_list$o_assumptions_1 = "We assume that there is no temporal changes in environmental variables, that the abiotic variables is the sole predictor of species distributions other than biotic variables"

### Algorithms  ###
obtain_subsection_ids(section_name = "Overview", "Algorithms")

obtain_description("o_algorithms_1")
input_list$o_assumptions_1 = "glm; svm; gaussian process model"
obtain_description("o_algorithms_2")
input_list$o_assumptions_2 = "A variety of models were used without making run time too extensive"
obtain_description("o_algorithms_3")
input_list$o_assumptions_3 = "We calculated a mean weighted average based on model performance"

### Workflow ###
obtain_subsection_ids(section_name = "Overview", "Workflow") 

obtain_description("o_workflow_1")
input_list$o_workflow_1 = "Species occurence data from the Cairngorms, Scotland was obtained by download from GBIF. We filtered environmental variables to only include environment data from within a 5 km buffer of recorded occurences, and conducted spatial thinning. Using 4-fold partitioning, a series of spatial models were developed and validated. An ensemble model was created from the model series. We corrected for overprediction using posteriori methods"

### Software ###
obtain_subsection_ids(section_name = "Overview", "Software")

obtain_description("o_software_1")

# Get session information
sess_info <- sessionInfo()

# Extract information about loaded packages
loaded_packages <- sess_info$otherPkgs

# Concatenate package names with their versions
package_version_strings <- sapply(names(loaded_packages), function(pkg) {
  paste(pkg, "version", loaded_packages[[pkg]]$Version, sep = " ")
})

# Combine into a single long string, separated by commas and spaces
packages_versions <- paste(package_version_strings, collapse = " \n\n")

input_list$o_software_1 = paste("Written using", R.Version()$version.string, "with packages:\n\n", packages_versions)
obtain_description("o_software_2")
input_list$o_software_2 = "https://github.com/BioDT/uc-ces/tree/main/biodiversity_model"
obtain_description("o_software_3")
input_list$o_software_3 = paste("data obtained from GBIF API with DOI:", doi)

#### Data ####
### Biodiversity data ###
obtain_subsection_ids(section_name = "Data", "Biodiversity data") 

obtain_description("d_bio_1")
input_list$d_bio_1 = paste("Species: ", target_species,
      ", phylum: ", gbif_data %>% filter(scientificName == target_species) %>% first() %>% pull(phylum) %>% unique(), ", order: ", gbif_data %>% filter(scientificName == target_species) %>% first() %>% pull(order) %>% unique(),
      ", family: ", gbif_data %>% filter(scientificName == target_species) %>% first() %>% pull(family) %>% unique(), sep = "")
obtain_description("d_bio_2")
input_list$d_bio_2 = "GBIF taxonomic backbone"
obtain_description("d_bio_3")
input_list$d_bio_3 = "species"
obtain_description("d_bio_4")
input_list$d_bio_4 = paste0("data obtained from GBIF API with DOI: ", doi, " at datetime: " access_datetime)
obtain_description("d_bio_5")
input_list$d_bio_5 = "opportunistic data"
obtain_description("d_bio_6")
input_list$d_bio_6 = paste("species: ", target_species, ", sample size = ", gbif_data %>% filter(scientificName == target_species) %>% nrow(), sep = "")
obtain_description("d_bio_7")
input_list$d_bio_7 = "No mask was used" # may be filled programatically
obtain_description("d_bio_8")
input_list$d_bio_8 = paste0("Spatial thinning: ", script_search("occfilt_env"), ifelse(script_search("occfilt_env"), "\n\nThinned occurrences based on environmental space", ""), "\n\n",
"temporal thinning: FALSE"
)
obtain_description("d_bio_9")
input_list$d_bio_9 = "no cleaning/filtering steps"
obtain_description("d_bio_10")
input_list$d_bio_10 = "not applicable"
obtain_description("d_bio_11")
input_list$d_bio_11 = paste0("Species occurences plotted for only species: ", target_species, "\n\n", "Spatial buffer: ", script_search("calib_area"), ifelse(script_search("calib_area"), "\n\nEstablished spatial buffers from occurences with 5 km radius", ""))
obtain_description("d_bio_12")
input_list$d_bio_12 = ""

### Data partitioning ###
obtain_subsection_ids(section_name = "Data", "Data partitioning") 

obtain_description("d_part_1")
input_list$d_part_1 = paste0("random partitioning: ", script_search("part_random"), ifelse(script_search("part_random"), paste("\n\n", "Conducted in flexsdm using 4 fold random partitioning"), ""))
obtain_description("d_part_2")
input_list$d_part_2 = "we calculate TSS, the threshold at which sensitivity and specificity are equal, as the performance metric used for selecting the best combination of hyper-parameter values in the tuned Maximum Entropy model"
obtain_description("d_part_3")
input_list$d_part_3 = paste0("Random partitioning: ", script_search("part_random"), ifelse(script_search("part_random"), paste("\n\n", "Conducted in flexsdm using 4 fold random partitioning"), ""))

### Predictor variables ###
obtain_subsection_ids(section_name = "Data", "Predictor variables") 

obtain_description("d_pred_1")
input_list$d_pred_1 = paste(names(env_data), collapse = ", ")
obtain_description("d_pred_2")
input_list$d_pred_2 = "Google earth engine"

extent <- ext(env_data)
obtain_description("d_pred_3")
input_list$d_pred_3_xmin = extent[1]
input_list$d_pred_3_xmax = extent[2]
input_list$d_pred_3_ymin = extent[3]
input_list$d_pred_3_ymax = extent[4]

obtain_description("d_pred_4")
input_list$d_pred_4 = "0.1 km"
obtain_description("d_pred_5")
input_list$d_pred_5 = crs(env_data, describe = T)$name
obtain_description("d_pred_6")
input_list$d_pred_6 = "No temporal extent"
obtain_description("d_pred_7")
input_list$d_pred_7 = "No temporal resolution"
obtain_description("d_pred_8")
input_list$d_pred_8 = "no upscaling/downscaling"
obtain_description("d_pred_9")
input_list$d_pred_9 = "" # Do we know of any biases
obtain_description("d_pred_10")
input_list$d_pred_10 = "" # What is "dimension reduction of variables"?

### Transfer data ###
obtain_subsection_ids(section_name = "Data", "Transfer data") 

obtain_description("d_proj_1")
input_list$d_proj_1 = paste0("data obtained from GBIF API with DOI: ", doi, " at datetime: " access_datetime)
obtain_description("d_proj_2")
input_list$d_proj_2_xmin <- "Not applicable"
input_list$d_proj_2_xmax <- "Not applicable"
input_list$d_proj_2_ymin <- "Not applicable"
input_list$d_proj_2_ymax <- "Not applicable"
obtain_description("d_proj_3")
input_list$d_proj_3 = "Not applicable"
obtain_description("d_proj_4")
input_list$d_proj_4 = "Not applicable"
obtain_description("d_proj_5")
input_list$d_proj_5 = "Not applicable"
obtain_description("d_proj_6")
input_list$d_proj_6 = "Not applicable"
obtain_description("d_proj_7")
input_list$d_proj_7 = "Not applicable"
obtain_description("d_proj_8")
input_list$d_proj_8 = "Not applicable"

#### Model ####
### Variable pre-selection ###
obtain_subsection_ids(section_name = "Model", "Variable pre-selection")

obtain_description("m_preselect_1")
input_list$m_preselect_1 = "Not applicable"

### Multicollinearity ###
obtain_subsection_ids(section_name = "Model", "Multicollinearity")
obtain_description("m_multicol_1")
input_list$m_multicol_1 = "No methods used to handle collinearity"

### Model settings ###
obtain_subsection_ids(section_name = "Model", "Model settings")
obtain_description("m_settings_1")

# Create values for the m_settings_1 table
input_list$m_settings_1 <- data.frame(
  Model = c("Gaussian", "GLM", "SVM"),
  Family = c("gaussian", "gaussian", NA),
  Formula = paste("predictors:", paste(names(env_data), collapse = "; ")),
  Weights = "none",
  Notes = ""
)
obtain_description("m_settings_2")
input_list$m_settings_2 <- "Not applicable"

### Model estimates ###
obtain_subsection_ids(section_name = "Model", "Model estimates")

obtain_description("m_estim_1")
input_list$m_estim_1 <- "Not applicable"
obtain_description("m_estim_2")
input_list$m_estim_2 <- "No quantification"
obtain_description("m_estim_3")
input_list$m_estim_3 <- "No assessment"

### Model selection - model averaging - ensembles ###
obtain_subsection_ids(section_name = "Model", "Model selection - model averaging - ensembles")

obtain_description("m_selection_1")
input_list$m_selection_1 <- "We included all environment variables recorded in a model input raster spanning the Cairngorms, Scotland"
obtain_description("m_selection_2")
input_list$m_selection_2 <- "No variable weights were used"
obtain_description("m_selection_3")
input_list$m_selection_3 <- "Occurences obtained from the Global Biodiversity Information Facility (GBIF), with pseudo replication of absences. See model settings table for model classes and parameters"

### Analysis and Correction of non-independence ###
obtain_subsection_ids(section_name = "Model", "Analysis and Correction of non-independence")

obtain_description("m_depend_1")
input_list$m_depend_1 <- "No method"
obtain_description("m_depend_2")
input_list$m_depend_2 <- "No method"
obtain_description("m_depend_3")
input_list$m_depend_3 <- "No method"

### Threshold selection ###
obtain_subsection_ids(section_name = "Model", "Threshold selection")

obtain_description("m_threshold_1")
input_list$m_threshold_1 <- "Not applicable"

#### Assessment ####
### Performance statistics ###
obtain_subsection_ids(section_name = "Assessment", "Performance statistics")

obtain_description("a_perform_1")
input_list$a_perform_1 <- "Not applicable"
obtain_description("a_perform_2")
input_list$a_perform_2 <- "For each model, we selected three threshold values to generate binary suitability predictions: the threshold that maximizes TSS (max_sens_spec), the threshold at which sensitivity and specificity are equal (equal_sens_spec), and the threshold at which the Sorenson index is highest (max_sorenson)."
obtain_description("a_perform_3")
input_list$a_perform_3 <- "Not applicable."

### Plausibility check ###
obtain_subsection_ids(section_name = "Assessment", "Plausibility check")

obtain_description("a_plausibility_1")
input_list$a_plausibility_1 <- "No response plots"
obtain_description("a_plausibility_2")
input_list$a_plausibility_2 <- "No expert judgements"

#### Prediction ####
### Prediction output ###
obtain_subsection_ids(section_name = "Prediction", "Prediction output")

obtain_description("p_output_1")
input_list$p_output_1 <- "Species proportional occurence"
obtain_description("p_output_2")
input_list$p_output_2 <- paste0("Adjustments for overprediction: ", script_search("msdm_posteriori"), ifelse(script_search("msdm_posteriori"), "\n\nThe overprediction of SDMs was corrected for based on occurrence records and suitability patterns.", ""))

### Uncertainty quantification ###
obtain_subsection_ids(section_name = "Prediction", "Uncertainty quantification")

obtain_description("p_uncertainty_1")
input_list$p_uncertainty_1 <- "Not applicable"
obtain_description("p_uncertainty_2")
input_list$p_uncertainty_2 <- "The models are trained using GBIF datasets. There may be biases introduced by the method(s) of data collection and source contributor(s)"
obtain_description("p_uncertainty_3")
input_list$p_uncertainty_3 <- "Not applicable"
obtain_description("p_uncertainty_4")
input_list$p_uncertainty_4 <- ""
obtain_description("p_uncertainty_5")
input_list$p_uncertainty_5 <- "No visualisation or treatment"
```

### Render ODMAP report

Here, we generate a final report for ODMAP as a word document to be included as supplementary information. 
```{r}
odmap_dict <- read_csv("odmap_dict.csv")
completed_fields <- read.csv("C:/Users/dylcar/OneDrive - UKCEH/Desktop/BioDT/uc-ces/metadata/biodiversity_model_od_map_fields.csv")
odmap_dict <- left_join(odmap_dict, completed_fields)

authors_string = paste(input_list$first_name, input_list$last_name, collapse = ", ")
  # Render the R Markdown to a Word document
render(
  input = file.path(getwd(), "ODMAP_generate.Rmd"),
  output_format = "word_document",
  output_file = file.path(getwd(), "sdm_odmap.docx"))

shell.exec("sdm_odmap.docx")

```